{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2.1 - Нейронные сети\n",
    "\n",
    "В этом задании вы реализуете и натренируете настоящую нейроную сеть своими руками!\n",
    "\n",
    "В некотором смысле это будет расширением прошлого задания - нам нужно просто составить несколько линейных классификаторов вместе!\n",
    "\n",
    "<img src=\"https://i.redd.it/n9fgba8b0qr01.png\" alt=\"Stack_more_layers\" width=\"400px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_svhn, random_split_train_val\n",
    "from gradient_check import check_layer_gradient, check_layer_param_gradient, check_model_gradient\n",
    "from layers import FullyConnectedLayer, ReLULayer\n",
    "from model import TwoLayerNet\n",
    "from trainer import Trainer, Dataset\n",
    "from optim import SGD, MomentumSGD\n",
    "from metrics import multiclass_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загружаем данные\n",
    "\n",
    "И разделяем их на training и validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_neural_network(train_X, test_X):\n",
    "    train_flat = train_X.reshape(train_X.shape[0], -1).astype(float) / 255.0\n",
    "    test_flat = test_X.reshape(test_X.shape[0], -1).astype(float) / 255.0\n",
    "    \n",
    "    # Subtract mean\n",
    "    mean_image = np.mean(train_flat, axis = 0)\n",
    "    train_flat -= mean_image\n",
    "    test_flat -= mean_image\n",
    "    \n",
    "    return train_flat, test_flat\n",
    "    \n",
    "train_X, train_y, test_X, test_y = load_svhn(\"data\", max_train=10000, max_test=1000)    \n",
    "train_X, test_X = prepare_for_neural_network(train_X, test_X)\n",
    "# Split train into train and val\n",
    "train_X, train_y, val_X, val_y = random_split_train_val(train_X, train_y, num_val = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как всегда, начинаем с кирпичиков\n",
    "\n",
    "Мы будем реализовывать необходимые нам слои по очереди. Каждый слой должен реализовать:\n",
    "- прямой проход (forward pass), который генерирует выход слоя по входу и запоминает необходимые данные\n",
    "- обратный проход (backward pass), который получает градиент по выходу слоя и вычисляет градиент по входу и по параметрам\n",
    "\n",
    "Начнем с ReLU, у которого параметров нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement ReLULayer layer in layers.py\n",
    "# Note: you'll need to copy implementation of the gradient_check function from the previous assignment\n",
    "\n",
    "X = np.array([[1,-2,3],\n",
    "              [-1, 2, 0.1]\n",
    "              ])\n",
    "\n",
    "assert check_layer_gradient(ReLULayer(), X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь реализуем полносвязный слой (fully connected layer), у которого будет два массива параметров: W (weights) и B (bias).\n",
    "\n",
    "Все параметры наши слои будут использовать для параметров специальный класс `Param`, в котором будут храниться значения параметров и градиенты этих параметров, вычисляемые во время обратного прохода.\n",
    "\n",
    "Это даст возможность аккумулировать (суммировать) градиенты из разных частей функции потерь, например, из cross-entropy loss и regularization loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement FullyConnected layer forward and backward methods\n",
    "assert check_layer_gradient(FullyConnectedLayer(3, 4), X)\n",
    "# TODO: Implement storing gradients for W and B\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'W')\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создаем нейронную сеть\n",
    "\n",
    "Теперь мы реализуем простейшую нейронную сеть с двумя полносвязным слоями и нелинейностью ReLU. Реализуйте функцию `compute_loss_and_gradients`, она должна запустить прямой и обратный проход через оба слоя для вычисления градиентов.\n",
    "\n",
    "Не забудьте реализовать очистку градиентов в начале функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for inputLayerW\n",
      "Gradient check passed!\n",
      "Checking gradient for inputLayerB\n",
      "Gradient check passed!\n",
      "Checking gradient for outputLayerW\n",
      "Gradient check passed!\n",
      "Checking gradient for outputLayerB\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: In model.py, implement compute_loss_and_gradients function\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 0)\n",
    "loss = model.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "\n",
    "# TODO Now implement backward pass and aggregate all of the params\n",
    "check_model_gradient(model, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь добавьте к модели регуляризацию - она должна прибавляться к loss и делать свой вклад в градиенты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for inputLayerW\n",
      "Gradient check passed!\n",
      "Checking gradient for inputLayerB\n",
      "Gradient check passed!\n",
      "Checking gradient for outputLayerW\n",
      "Gradient check passed!\n",
      "Checking gradient for outputLayerB\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Now implement l2 regularization in the forward and backward pass\n",
    "model_with_reg = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 1e1)\n",
    "loss_with_reg = model_with_reg.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "assert loss_with_reg > loss and not np.isclose(loss_with_reg, loss), \\\n",
    "    \"Loss with regularization (%2.4f) should be higher than without it (%2.4f)!\" % (loss, loss_with_reg)\n",
    "\n",
    "check_model_gradient(model_with_reg, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также реализуем функцию предсказания (вычисления значения) модели на новых данных.\n",
    "\n",
    "Какое значение точности мы ожидаем увидеть до начала тренировки?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, implement predict function!\n",
    "\n",
    "# TODO: Implement predict function\n",
    "# What would be the value we expect?\n",
    "multiclass_accuracy(model_with_reg.predict(train_X[:30]), train_y[:30]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Допишем код для процесса тренировки\n",
    "\n",
    "Если все реализовано корректно, значение функции ошибки должно уменьшаться с каждой эпохой, пусть и медленно. Не беспокойтесь пока про validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.302029, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301685, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301851, Train accuracy: 0.148222, val accuracy: 0.140000\n",
      "Loss: 2.302623, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302031, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301124, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302831, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301638, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302170, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302117, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302455, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302807, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302832, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302390, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.303278, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301772, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302333, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302433, Train accuracy: 0.148222, val accuracy: 0.140000\n",
      "Loss: 2.301941, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302173, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    }
   ],
   "source": [
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate = 1e-2)\n",
    "\n",
    "# TODO Implement missing pieces in Trainer.fit function\n",
    "# You should expect loss to go down every epoch, even if it's slow\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc7ae6aebe0>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Улучшаем процесс тренировки\n",
    "\n",
    "Мы реализуем несколько ключевых оптимизаций, необходимых для тренировки современных нейросетей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Уменьшение скорости обучения (learning rate decay)\n",
    "\n",
    "Одна из необходимых оптимизаций во время тренировки нейронных сетей - постепенное уменьшение скорости обучения по мере тренировки.\n",
    "\n",
    "Один из стандартных методов - уменьшение скорости обучения (learning rate) каждые N эпох на коэффициент d (часто называемый decay). Значения N и d, как всегда, являются гиперпараметрами и должны подбираться на основе эффективности на проверочных данных (validation data). \n",
    "\n",
    "В нашем случае N будет равным 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Implement learning rate decay inside Trainer.fit method\n",
    "# Decay should happen once per epoch\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate_decay=0.99)\n",
    "\n",
    "initial_learning_rate = trainer.learning_rate\n",
    "loss_history, train_history, val_history = trainer.fit()\n",
    "\n",
    "assert trainer.learning_rate < initial_learning_rate, \"Learning rate should've been reduced\"\n",
    "assert trainer.learning_rate > 0.5*initial_learning_rate, \"Learning rate shouldn'tve been reduced that much!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Накопление импульса (Momentum SGD)\n",
    "\n",
    "Другой большой класс оптимизаций - использование более эффективных методов градиентного спуска. Мы реализуем один из них - накопление импульса (Momentum SGD).\n",
    "\n",
    "Этот метод хранит скорость движения, использует градиент для ее изменения на каждом шаге, и изменяет веса пропорционально значению скорости.\n",
    "(Физическая аналогия: Вместо скорости градиенты теперь будут задавать ускорение, но будет присутствовать сила трения.)\n",
    "\n",
    "```\n",
    "velocity = momentum * velocity - learning_rate * gradient \n",
    "w = w + velocity\n",
    "```\n",
    "\n",
    "`momentum` здесь коэффициент затухания, который тоже является гиперпараметром (к счастью, для него часто есть хорошее значение по умолчанию, типичный диапазон -- 0.8-0.99).\n",
    "\n",
    "Несколько полезных ссылок, где метод разбирается более подробно:  \n",
    "http://cs231n.github.io/neural-networks-3/#sgd  \n",
    "https://distill.pub/2017/momentum/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement MomentumSGD.update function in optim.py\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, MomentumSGD(), learning_rate=1e-4, learning_rate_decay=0.99)\n",
    "\n",
    "# You should see even better results than before!\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ну что, давайте уже тренировать сеть!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Последний тест - переобучимся (overfit) на маленьком наборе данных\n",
    "\n",
    "Хороший способ проверить, все ли реализовано корректно - переобучить сеть на маленьком наборе данных.  \n",
    "Наша модель обладает достаточной мощностью, чтобы приблизить маленький набор данных идеально, поэтому мы ожидаем, что на нем мы быстро дойдем до 100% точности на тренировочном наборе. \n",
    "\n",
    "Если этого не происходит, то где-то была допущена ошибка!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = 15\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=1e-1, num_epochs=150, batch_size=5)\n",
    "\n",
    "# You should expect this to reach 1.0 training accuracy \n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь найдем гипепараметры, для которых этот процесс сходится быстрее.\n",
    "Если все реализовано корректно, то существуют параметры, при которых процесс сходится в **20** эпох или еще быстрее.\n",
    "Найдите их!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, tweak some hyper parameters and make it train to 1.0 accuracy in 20 epochs or less\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "# TODO: Change any hyperparamers or optimizators to reach training accuracy in 20 epochs\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=1e-1, num_epochs=20, batch_size=5)\n",
    "\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Итак, основное мероприятие!\n",
    "\n",
    "Натренируйте лучшую нейросеть! Можно добавлять и изменять параметры, менять количество нейронов в слоях сети и как угодно экспериментировать. \n",
    "\n",
    "Добейтесь точности лучше **60%** на validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's train the best one-hidden-layer network we can\n",
    "\n",
    "learning_rates = 1e-4\n",
    "reg_strength = 1e-3\n",
    "learning_rate_decay = 0.999\n",
    "hidden_layer_size = 128\n",
    "num_epochs = 200\n",
    "batch_size = 64\n",
    "\n",
    "best_classifier = None\n",
    "best_val_accuracy = None\n",
    "\n",
    "loss_history = []\n",
    "train_history = []\n",
    "val_history = []\n",
    "\n",
    "# TODO find the best hyperparameters to train the network\n",
    "# Don't hesitate to add new values to the arrays above, perform experiments, use any tricks you want\n",
    "# You should expect to get to at least 40% of valudation accuracy\n",
    "# Save loss/train/history of the best classifier to the variables above\n",
    "\n",
    "print('best validation accuracy achieved: %f' % best_val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "plt.subplot(211)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(loss_history)\n",
    "plt.subplot(212)\n",
    "plt.title(\"Train/validation accuracy\")\n",
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как обычно, посмотрим, как наша лучшая модель работает на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = best_classifier.predict(test_X)\n",
    "test_accuracy = multiclass_accuracy(test_pred, test_y)\n",
    "print('Neural net test set accuracy: %f' % (test_accuracy, ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
